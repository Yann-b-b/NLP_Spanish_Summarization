{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannbaglinbunod/miniconda3/envs/w/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yannbaglinbunod/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/yannbaglinbunod/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yannbaglinbunod/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m df_results\u001b[38;5;241m.\u001b[39mto_csv(csv_filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Display the saved results\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mace_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[1;32m     43\u001b[0m tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mdf_results)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load as load_metric\n",
    "\n",
    "# File path for Phi-1.5B summaries\n",
    "summary_file = \"/Users/yannbaglinbunod/Desktop/NLP/PROJECT/Evaluations/test_summaries/test_summaries_Phi-1.5B.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df_summaries = pd.read_csv(summary_file)\n",
    "\n",
    "# Extract generated and reference summaries\n",
    "hypotheses = df_summaries[\"generated_summary\"].tolist()\n",
    "references = [[r] for r in df_summaries[\"reference_summary\"]]\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = load_metric(\"bleu\")\n",
    "meteor = load_metric(\"meteor\")\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Compute scores\n",
    "bleu_score = bleu.compute(predictions=hypotheses, references=references)[\"bleu\"]\n",
    "meteor_score = meteor.compute(predictions=hypotheses, references=references)[\"meteor\"]\n",
    "rouge_scores = rouge.compute(predictions=hypotheses, references=references)\n",
    "\n",
    "# Store results in required format\n",
    "results = {\n",
    "    \"Model\": [\"Phi-1.5B\"],\n",
    "    \"BLEU\": [bleu_score],\n",
    "    \"METEOR\": [meteor_score],\n",
    "    \"ROUGE-1\": [rouge_scores[\"rouge1\"]],\n",
    "    \"ROUGE-2\": [rouge_scores[\"rouge2\"]],\n",
    "    \"ROUGE-L\": [rouge_scores[\"rougeL\"]]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save in the correct CSV format\n",
    "csv_filename = \"evaluation_metrics.csv\"\n",
    "df_results.to_csv(csv_filename, index=False, mode=\"a\", header=False)\n",
    "\n",
    "# Display the saved results\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Evaluation Metrics\", dataframe=df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
